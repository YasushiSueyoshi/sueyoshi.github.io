[{"category": "Chapter 1", "question": "あるECサイトで、顧客の過去の購買履歴や閲覧履歴を分析し、その顧客が次に購入しそうな商品を予測するシステムを構築したいと考えています。この場合、最も適している機械学習の手法はどれですか？", "answers": ["過去のデータに「正解」のラベル（購入したかどうか）を付けて学習させる「教師あり学習」", "データに潜むパターンをAI自らが見つけ出す「教師なし学習」", "AIが試行錯誤を繰り返しながら、最適な行動を学習する「強化学習」", "人間の専門家の知識をルールとして記述する「エキスパートシステム」"], "correctAnswer": "過去のデータに「正解」のラベル（購入したかどうか）を付けて学習させる「教師あり学習」", "explanation": "「商品Aを購入した顧客は、商品Bも購入する傾向がある」といった過去の正解データ（購買履歴）から未来の行動（次の購入）を予測するのは、教師あり学習の典型的な応用例です。特に、特定の結果を予測する「分類」問題に該当します。", "source": "第1章 機械学習の基本的な種類"}, {"category": "Chapter 1", "question": "ある工場で、製品の外観検査を自動化するためにAIを導入しました。AIは大量の「正常な製品」の画像のみを学習し、それらの特徴と大きく異なるものを「異常品」として検知します。このアプローチに最も近い機械学習の手法はどれですか？", "answers": ["「正常品」と「異常品」の両方のラベルを付けて学習させる「教師あり学習」", "データの構造やパターンから「外れ値」を検出する「教師なし学習」", "検査員のフィードバックを報酬として受け取り、精度を高めていく「強化学習」", "事前に定義された欠陥のルールリストと照合する「ルールベースチェック」"], "correctAnswer": "データの構造やパターンから「外れ値」を検出する「教師なし学習」", "explanation": "この例では、AIは「正常とは何か」だけを学習し、そこから逸脱するものを異常としています。これは、明確な「異常」のラベルがない状態で、データ自身の分布から外れ値を検出する教師なし学習の「異常検知」と呼ばれるタスクに分類されます。", "source": "第1章 機械学習の基本的な種類"}, {"category": "Chapter 1", "question": "ディープラーニングのモデルをトレーニングする際、学習データに対しては非常に高い精度を出すものの、未知の新しいデータ（テストデータ）に対しては精度が大幅に低下してしまう現象が確認されました。この現象を何と呼びますか？", "answers": ["ハルシネーション", "過学習（Overfitting）", "学習不足（Underfitting）", "モード崩壊"], "correctAnswer": "過学習（Overfitting）", "explanation": "過学習は、モデルが学習データに過剰に適合し、データに含まれるノイズや偶発的な特徴まで学習してしまった結果、汎用的な予測能力（汎化性能）を失ってしまう状態を指します。モデルの複雑さを下げたり、学習データの量を増やしたりすることで緩和できる場合があります。", "source": "第1章 機械学習における課題"}, {"category": "Chapter 1", "question": "主に画像認識の分野で大きな成功を収めているディープラーニングのモデルで、画像内の物体の位置や形状が多少変化しても、それを同一の物体として認識できる頑健性を持つことが特徴のアーキテクチャは何ですか？", "answers": ["回帰型ニューラルネットワーク (RNN)", "畳み込みニューラルネットワーク (CNN)", "オートエンコーダ (AE)", "多層パーセプトロン (MLP)"], "correctAnswer": "畳み込みニューラルネットワーク (CNN)", "explanation": "CNNは、画像から局所的な特徴を抽出する「畳み込み層」と、特徴の位置ずれを吸収し情報を圧縮する「プーリング層」を組み合わせることで、画像の空間的な階層構造を効率的に学習できます。これにより、平行移動などに対する頑健性を獲得しています。", "source": "第1章 ディープラーニングの代表的なモデル"}, {"category": "Chapter 1", "question": "自然言語処理の分野で広く用いられるRNN（回帰型ニューラルネットワーク）には、文が長くなるほど過去の情報を忘れてしまい、長期的な依存関係を学習するのが難しいという課題がありました。この課題を克服するために考案されたモデルはどれですか？", "answers": ["パーセプトロン", "サポートベクターマシン (SVM)", "LSTM (Long Short-Term Memory)", "k-means法"], "correctAnswer": "LSTM (Long Short-Term Memory)", "explanation": "LSTMは、RNNの内部に「ゲート」と呼ばれる機構を導入し、どの情報を記憶し、どの情報を忘れるかを選択的に制御できるようにしたモデルです。これにより、長期的な文脈を記憶し、より自然な文章生成や機械翻訳などが可能になりました。", "source": "第1章 ディープラーニングの代表的なモデル"}, {"category": "Chapter 1", "question": "あるお掃除ロボットが、部屋の中を効率的に掃除するためのルートを学習しています。壁にぶつかったらマイナスの評価、ゴミを吸引したらプラスの評価、というフィードバックを受け取りながら、最も評価が高くなるような動き方を自ら見つけ出そうとします。この学習アプローチを何と呼びますか？", "answers": ["教師あり学習", "教師なし学習", "強化学習", "半教師あり学習"], "correctAnswer": "強化学習", "explanation": "強化学習は、エージェント（この場合はお掃除ロボット）が環境（部屋）の中で行動し、その結果得られる報酬（評価）を最大化するように学習する手法です。明確な「正解」のデータを与えるのではなく、試行錯誤を通じて最適な方策（policy）を学習します。", "source": "第1章 機械学習の基本的な種類"}, {"category": "Chapter 1", "question": "AIの歴史において、人間の脳の神経細胞（ニューロン）の仕組みにヒントを得て、多数の単純な処理ユニットを結合することで知的な処理を実現しようとする考え方やアプローチを何と呼びますか？", "answers": ["記号主義", "コネクショニズム", "行動主義", "遺伝的アルゴリズム"], "correctAnswer": "コネクショニズム", "explanation": "コネクショニズムは、脳の神経回路網（ニューラルネットワーク）の構造と機能をモデル化することで、知能の謎に迫ろうとするアプローチです。現在のディープラーニングの隆盛は、このコネクショニズムの考え方に基づいています。", "source": "第1章 AIの歴史とアプローチ"}, {"category": "Chapter 1", "question": "ある銀行が、顧客の年齢、年収、借入額、過去の返済履歴などのデータを用いて、その顧客が将来ローンを返済できなくなるかどうかを予測するモデルを構築しました。このタスクは、教師あり学習の中でどのように分類されますか？", "answers": ["回帰", "分類", "クラスタリング", "次元削減"], "correctAnswer": "分類", "explanation": "このタスクの目的は、「返済できなくなる」か「返済できる」かという、あらかじめ定義されたカテゴリ（クラス）に顧客を分類することです。このように、離散的なラベルを予測する問題を「分類」と呼びます。一方、住宅価格のように連続的な数値を予測する問題は「回帰」です。", "source": "第1章 教師あり学習のタスク"}, {"category": "Chapter 1", "question": "あるマーケティング担当者が、自社の顧客データベースに存在する数万人の顧客を、購買傾向や興味関心に基づいていくつかのグループに自動的に分類したいと考えています。各顧客がどのグループに属するかという正解ラベルはない状態です。この場合に適した手法はどれですか？", "answers": ["k-近傍法", "サポートベクターマシン", "クラスタリング", "線形回帰"], "correctAnswer": "クラスタリング", "explanation": "クラスタリングは、教師なし学習の一種で、データ間の類似度に基づいて、データを自然なグループ（クラスタ）に分割する手法です。顧客セグメンテーションや異常検知など、正解データがない状況でデータの構造を理解するために広く用いられます。", "source": "第1章 教師なし学習のタスク"}, {"category": "Chapter 1", "question": "ディープラーニングの学習プロセスにおいて、モデルの予測結果と実際の正解値との間の「誤差」や「隔たり」を定量的に測るために用いられる指標を何と呼びますか？", "answers": ["活性化関数", "損失関数", "最適化アルゴリズム", "学習率"], "correctAnswer": "損失関数", "explanation": "損失関数（またはコスト関数）は、モデルの性能の悪さを示す指標です。ディープラーニングの学習の目的は、この損失関数の値を最小化するような、モデルの内部パラメータ（重みやバイアス）を見つけ出すことにあります。", "source": "第1章 ディープラーニングの学習プロセス"}, {"category": "Chapter 1", "question": "ディープラーニングモデルの学習において、損失関数の値を最小化するために、モデルのパラメータをどの方向にどれだけ更新すればよいかを決定するアルゴリズムの総称は何ですか？", "answers": ["オプティマイザ（最適化アルゴリズム）", "レギュレータ（正則化）", "アクティベータ（活性化関数）", "イニシャライザ（初期化）"], "correctAnswer": "オプティマイザ（最適化アルゴリズム）", "explanation": "オプティマイザは、損失関数の勾配（傾き）情報を基に、パラメータを効率的に更新していくための手法です。代表的なものに「勾配降下法」や、その改良版である「Adam」などがあります。", "source": "第1章 ディープラーニングの学習プロセス"}, {"category": "Chapter 1", "question": "ニューラルネットワークにおいて、入力された信号の総和を次の層にどのように出力（発火）させるかを決定する非線形の関数を何と呼びますか？この関数のおかげで、ネットワークは複雑なパターンを学習できます。", "answers": ["損失関数", "活性化関数", "評価関数", "伝達関数"], "correctAnswer": "活性化関数", "explanation": "活性化関数は、ニューロンの発火を模倣する役割を持ちます。もし活性化関数が線形（単純な比例関係）だと、ニューラルネットワーク全体も線形な処理しかできず、層を深くする意味がなくなってしまいます。ReLUやシグモイド関数などが代表的です。", "source": "第1章 ニューラルネットワークと活性化関数"}, {"category": "Chapter 1", "question": "ある研究者が、非常に深い（層の数が多い）ニューラルネットワークを学習させようとしたところ、入力層に近い層の重みがほとんど更新されず、学習が全く進まないという問題に直面しました。この現象を何と呼びますか？", "answers": ["勾配消失問題", "勾配爆発問題", "過学習", "次元の呪い"], "correctAnswer": "勾配消失問題", "explanation": "誤差逆伝播法において、出力層から入力層に向かって誤差を伝播させる際、活性化関数の影響などで勾配（誤差の信号）がどんどん小さくなり、0に近くなってしまう現象です。これにより、入力層に近い部分のパラメータが更新されなくなり、学習が停滞します。", "source": "第1章 ディープラーニングにおける課題"}, {"category": "Chapter 1", "question": "AIの歴史を振り返ったとき、1980年代から1990年代にかけて起こった第二次AIブームを牽引した技術は何ですか？この技術は、専門家の知識を「もし～ならば～」という形式のルールとしてコンピュータに教え込むものでした。", "answers": ["エキスパートシステム", "機械学習", "ディープラーニング", "遺伝的アルゴリズム"], "correctAnswer": "エキスパートシステム", "explanation": "エキスパートシステムは、特定の専門分野における専門家の意思決定能力をコンピュータ上で再現しようとするものです。医療診断や故障診断などの分野で実用化されましたが、知識の獲得や更新が難しいという課題がありました。", "source": "第1章 AIの歴史とブーム"}, {"category": "Chapter 1", "question": "2012年に開催された画像認識コンテスト（ILSVRC）で、ディープラーニングを用いたチーム「SuperVision」が圧勝し、第三次AIブームの火付け役となりました。この「SuperVision」が用いたアーキテクチャは何ですか？", "answers": ["RNN", "LSTM", "GAN", "CNN（畳み込みニューラルネットワーク）"], "correctAnswer": "CNN（畳み込みニューラルネットワーク）", "explanation": "このコンテストで用いられた「AlexNet」と呼ばれるCNNは、GPUを利用した大規模な学習により、従来の画像認識手法を大幅に上回る精度を達成しました。これがきっかけとなり、様々な分野でディープラーニングの研究・応用が爆発的に進展しました。", "source": "第1章 AIの歴史とブーム"}, {"category": "Chapter 1", "question": "ある株価予測モデルを構築する際、過去10年分の株価データのうち、最初の8年分をモデルの学習に用い、残りの2年分をモデルの性能評価のために取っておきました。この性能評価用のデータを何と呼びますか？", "answers": ["学習データ（訓練データ）", "検証データ", "テストデータ（評価データ）", "教師データ"], "correctAnswer": "テストデータ（評価データ）", "explanation": "テストデータは、モデルが学習の過程で一度も見ていない、未知のデータです。このテストデータに対する性能を評価することで、モデルがどれだけ新しいデータに対応できるか、すなわち「汎化性能」を測ることができます。", "source": "第1章 機械学習モデルの評価"}, {"category": "Chapter 1", "question": "機械学習モデルの学習において、学習データの一部を「検証データ」として確保しておくことがあります。この検証データの主な目的として、最も適切なものはどれですか？", "answers": ["モデルの最終的な汎化性能を測定するため", "学習の途中で、ハイパーパラメータ（学習率など）の調整や過学習の監視を行うため", "モデルの学習に用いる正解ラベルとして使用するため", "学習データの量を増やす（水増しする）ため"], "correctAnswer": "学習の途中で、ハイパーパラメータ（学習率など）の調整や過学習の監視を行うため", "explanation": "検証データは、学習中にモデルの性能を「検証」するために使われます。例えば、検証データに対する性能が悪化し始めたら、それは過学習が始まった兆候と判断し、学習を早期に終了する、といった判断に利用されます。", "source": "第1章 機械学習モデルの評価"}, {"category": "Chapter 1", "question": "ある病気の診断モデルを開発しました。このモデルの性能を評価する際、「実際に病気である人のうち、正しく病気であると予測できた人の割合」を特に重視したいと考えています。この指標は何ですか？", "answers": ["正解率 (Accuracy)", "適合率 (Precision)", "再現率 (Recall)", "F値 (F-measure)"], "correctAnswer": "再現率 (Recall)", "explanation": "再現率は「見逃し」をどれだけ減らせるかの指標です。病気の診断のように、見逃しが重大な結果につながるケースでは、再現率が特に重要な評価指標となります。偽陽性（病気でないのに病気と予測）が増える可能性とのトレードオフになります。", "source": "第1章 機械学習の評価指標"}, {"category": "Chapter 1", "question": "スパムメールフィルタを開発する際、「スパムでないメール（正常なメール）を、誤ってスパムと判定してしまう」ケースを可能な限り減らしたいと考えています。このとき、特に高めるべき指標はどれですか？", "answers": ["正解率 (Accuracy)", "適合率 (Precision)", "再現率 (Recall)", "特異度 (Specificity)"], "correctAnswer": "適合率 (Precision)", "explanation": "適合率は、「陽性（この場合はスパム）と予測したもののうち、実際に陽性であったものの割合」を示します。適合率が高いということは、スパムと判定したメールが本当にスパムである確率が高いことを意味し、正常なメールを誤判定するリスクが低いと言えます。", "source": "第1章 機械学習の評価指標"}, {"category": "Chapter 1", "question": "ディープラーニングのモデルが、学習データに過剰に適合してしまう「過学習」を防ぐための手法として、適切でないものはどれですか？", "answers": ["学習データのサンプル数を増やす", "モデルの構造をより複雑にする（層やノードを増やす）", "学習中にランダムに一部のノードを無効化する（ドロップアウト）", "モデルのパラメータが大きくなりすぎないように制約をかける（正則化）"], "correctAnswer": "モデルの構造をより複雑にする（層やノードを増やす）", "explanation": "モデルの構造を複雑にしすぎると、表現力が高まる一方で、学習データに含まれるノイズまで学習してしまい、過学習のリスクが高まります。過学習を防ぐには、むしろモデルを単純化したり、正則化やドロップアウトといったテクニックを用いたりするのが一般的です。", "source": "第1章 過学習とその対策"}, {"category": "Chapter 1", "question": "ある手書き数字認識モデルの学習が思うように進まず、学習データに対する精度すら低い状態にあります。このモデルは、データの特徴を十分に捉えきれていない可能性が考えられます。このような状態を何と呼びますか？", "answers": ["過学習（Overfitting）", "学習不足（Underfitting）", "勾配爆発", "サチュレーション"], "correctAnswer": "学習不足（Underfitting）", "explanation": "学習不足は、モデルの表現力が低すぎるか、学習が不十分であるために、学習データの特徴すら十分に学習できていない状態を指します。この場合、モデルをより複雑なものに変更したり、学習回数を増やしたりすることが対策として考えられます。", "source": "第1章 機械学習における課題"}, {"category": "Chapter 1", "question": "AI、機械学習、ディープラーニングの関係性を正しく表現しているものはどれですか？", "answers": ["AI、機械学習、ディープラーニングは、それぞれ全く異なる独立した技術分野である", "AIは機械学習を実現するための一手法であり、機械学習はディープラーニングの一分野である", "ディープラーニングは機械学習を実現するための一手法であり、機械学習はAIという広い概念に含まれる一分野である", "機械学習とディープラーニングは同義であり、AIを実現するための唯一の方法である"], "correctAnswer": "ディープラーニングは機械学習を実現するための一手法であり、機械学習はAIという広い概念に含まれる一分野である", "explanation": "AI（人工知知能）という最も広い概念があり、その中に「データから学習する能力」をコンピュータに与える機械学習という分野があります。そして、機械学習の様々な手法の中に、人間の脳の仕組みを模したニューラルネットワークを多層に重ねたディープラーニングという特定の手法が存在します。", "source": "第1章 AI・機械学習・ディープラーニングの関係"}, {"category": "Chapter 1", "question": "ある研究者が、手元にある大量の unlabeled data（正解ラベルのないデータ）と、ごく少量の labeled data（正解ラベルのあるデータ）の両方を使って、効率的にモデルを学習させたいと考えています。このような学習手法を何と呼びますか？", "answers": ["教師あり学習", "教師なし学習", "強化学習", "半教師あり学習"], "correctAnswer": "半教師あり学習", "explanation": "半教師あり学習は、大量のラベルなしデータからデータの分布や特徴を学習し、その知識を少量のラベルありデータを用いた学習に活かすアプローチです。ラベル付けのコストが高い場合に特に有効な手法とされています。", "source": "第1章 機械学習の様々な手法"}, {"category": "Chapter 1", "question": "CNN（畳み込みニューラルネットワーク）で用いられる「プーリング層」の主な役割として、最も適切なものはどれですか？", "answers": ["画像からエッジやコーナーなどの局所的な特徴を抽出する", "特徴マップのサイズを縮小し、計算量を削減すると同時に、位置ずれに対する頑健性を高める", "最終的な分類結果を出力する", "学習の過程で過学習を防ぐために、ランダムにニューロンを無効化する"], "correctAnswer": "特徴マップのサイズを縮小し、計算量を削減すると同時に、位置ずれに対する頑健性を高める", "explanation": "プーリング層は、畳み込み層で抽出された特徴マップの情報を圧縮する役割を持ちます。例えば、2x2の領域の最大値を取る「マックスプーリング」などがあり、これにより、特徴の細かい位置が多少ずれても、同じような出力が得られるようになります。", "source": "第1章 畳み込みニューラルネットワーク(CNN)"}, {"category": "Chapter 1", "question": "ディープラーニングの学習において、一度に処理するデータのかたまりのことを「バッチ」と呼びます。そして、全ての学習データをいくつかのバッチに分けて学習させる手法が一般的です。この手法の利点として、適切でないものはどれですか？", "answers": ["限られたメモリの計算機でも、大規模なデータセットを学習できる", "学習の安定化と高速化が期待できる", "学習プロセスにおけるノイズの役割を果たし、局所解に陥りにくくする効果がある", "常にデータセット全体を見て学習するため、最も正確な勾配を計算できる"], "correctAnswer": "常にデータセット全体を見て学習するため、最も正確な勾配を計算できる", "explanation": "バッチ学習（ミニバッチ学習）では、データセットの一部（バッチ）だけを見てパラメータを更新するため、計算される勾配は近似的なものになります。データセット全体を見て計算する方が勾配は正確ですが、計算コストが非常に高くなるため、通常はミニバッチ学習が用いられます。", "source": "第1章 ディープラーニングの学習テクニック"}, {"category": "Chapter 1", "question": "ディープラーニングの最適化アルゴリズムである「勾配降下法」において、一度のパラメータ更新でどれだけ移動するかを決定する重要なハイパーパラメータは何ですか？この値が大きすぎると学習が発散し、小さすぎると学習に時間がかかりすぎます。", "answers": ["学習率 (Learning Rate)", "バッチサイズ (Batch Size)", "エポック数 (Epochs)", "モーメンタム (Momentum)"], "correctAnswer": "学習率 (Learning Rate)", "explanation": "学習率は、損失関数の坂道を下る際の「歩幅」に例えられます。適切な学習率を設定することは、ディープラーニングの学習を成功させるための非常に重要な要素であり、様々な調整手法が提案されています。", "source": "第1章 ディープラーニングの学習テクニック"}, {"category": "Chapter 1", "question": "ある自然言語処理タスクで、単語をコンピュータが処理できる数値表現に変換する必要があります。このとき、「king」 - 「man」 + 「woman」 = 「queen」のように、単語の意味的な関係性をベクトル空間上の演算で表現できるような手法を何と呼びますか？", "answers": ["One-hotエンコーディング", "Bag-of-Words (BoW)", "単語埋め込み (Word Embedding)", "TF-IDF"], "correctAnswer": "単語埋め込み (Word Embedding)", "explanation": "単語埋め込みは、各単語を低次元（例：100次元）の実数ベクトルで表現する技術です。Word2Vecなどが代表的な手法で、これにより、単語間の意味的な類似度を計算したり、意味に基づいた演算を行ったりすることが可能になります。", "source": "第1章 自然言語処理の基礎"}, {"category": "Chapter 1", "question": "AI研究の究極的な目標の一つとして、特定のタスクだけでなく、人間のように様々な状況で柔軟に思考・学習できるAIの実現が挙げられます。このようなAIを何と呼びますか？", "answers": ["特化型AI (Narrow AI)", "汎用AI (General AI / AGI)", "強いAI", "弱いAI"], "correctAnswer": "汎用AI (General AI / AGI)", "explanation": "汎用AI（AGI: Artificial General Intelligence）は、特定の目的に限定されず、人間が持つような総合的な知能を持つAIを指します。現在存在するAIのほとんどは、画像認識や言語翻訳など、特定のタスクに特化した「特化型AI」です。", "source": "第1章 AIの種類と目標"}, {"category": "Chapter 2", "question": "ある画家が、自身の作風を学習させた画像生成AIに「星月夜のスタイルで描かれた東京の夜景」という指示を与え、新しい絵画を生成させました。このAIが行っていることに最も近いタスクはどれですか？", "answers": ["与えられた画像が本物か偽物かを判定する「識別」", "既存のデータから新しいデータを創造する「生成」", "大量のデータから特定の情報を検索する「検索」", "データの中から異常な値を検出する「異常検知」"], "correctAnswer": "既存のデータから新しいデータを創造する「生成」", "explanation": "生成AIは、学習したデータ（この場合は画家の作風）のパターンや特徴を捉え、それに基づいて新しい、かつオリジナルのデータ（東京の夜景の絵）を創造する能力を持ちます。これは識別系AIと対比される重要な特徴です。", "source": "第2章 生成AIの概要"}, {"category": "Chapter 2", "question": "「偽物の絵画を生成するAI」と「その偽物を見破るAI」を互いに競わせるように学習させることで、本物と見分けがつかないほど精巧な画像を生成できるようにする生成AIのモデルはどれですか？", "answers": ["変分オートエンコーダ (VAE)", "敵対的生成ネットワーク (GAN)", "拡散モデル (Diffusion Model)", "Transformer"], "correctAnswer": "敵対的生成ネットワーク (GAN)", "explanation": "GANは、生成器（Generator）と識別器（Discriminator）という2つのネットワークが敵対的に学習を進めるユニークなアーキテクチャです。この競争プロセスを通じて、生成器は非常に高品質なデータを生成する能力を獲得します。", "source": "第2章 代表的な生成モデル"}, {"category": "Chapter 2", "question": "近年、高品質な画像生成で注目を集めている「拡散モデル」に関する説明として、最も適切なものはどれですか？", "answers": ["2つのAIを競わせることで学習する", "元画像にノイズを加え、そのノイズを除去する過程を学習する", "入力データを低次元の空間に圧縮してから復元する", "文中の単語の関連性に注目して処理を行う"], "correctAnswer": "元画像にノイズを加え、そのノイズを除去する過程を学習する", "explanation": "拡散モデルは、データに徐々にノイズを加えていく順方向の過程と、ノイズだけの状態から元のデータを復元する逆方向の過程を学習します。この逆方向の過程を利用することで、ランダムなノイズから新しいデータを生成することができます。", "source": "第2章 代表的な生成モデル"}, {"category": "Chapter 2", "question": "ChatGPTのような大規模言語モデルの基盤技術であり、「文中のどの単語に注目すべきか」の重み付けを学習することで、文脈に応じた柔軟な情報処理を可能にした画期的なメカニズムは何ですか？", "answers": ["ゲート機構", "畳み込み", "アテンション機構 (Attention Mechanism)", "再帰的構造"], "correctAnswer": "アテンション機構 (Attention Mechanism)", "explanation": "アテンション機構は、Googleが2017年に発表した論文「Attention Is All You Need」で提唱され、その後の大規模言語モデルの発展に絶大な影響を与えました。RNNやCNNの構造に頼らず、単語間の関連性だけで文脈を捉えることを可能にしました。", "source": "第2章 Transformerとアテンション機構"}, {"category": "Chapter 2", "question": "ある企業が、自社製品に関する問い合わせ対応のために、汎用の大規模言語モデルを追加学習させ、自社製品に特化した知識を持つチャットボットを開発しました。このようなプロセスを何と呼びますか？", "answers": ["事前学習 (Pre-training)", "ファインチューニング (Fine-tuning)", "プロンプトエンジニアリング", "強化学習"], "correctAnswer": "ファインチューニング (Fine-tuning)", "explanation": "ファインチューニングは、大規模なデータで事前学習された汎用的な「基盤モデル」を、特定のタスクやドメインに適応させるために、少量の専門的なデータで追加学習させる手法です。これにより、効率的に高性能な特化モデルを開発できます。", "source": "第2章 基盤モデルとその活用"}, {"category": "Chapter 2", "question": "生成AIに特定のタスクを解かせる際、AIに役割（ペルソナ）を与え、出力形式を指定し、いくつかの例（Few-shot）を提示することで、回答の精度を高める一連の工夫を何と呼びますか？", "answers": ["ファインチューニング", "蒸留", "プロンプトエンジニアリング", "強化学習"], "correctAnswer": "プロンプトエンジニアリング", "explanation": "プロンプトエンジニアリングは、生成AIの能力を最大限に引き出すために、入力（プロンプト）を工夫する技術です。役割設定、出力形式の指定、Few-shotプロンプティングなどは、その代表的なテクニックです。", "source": "第2章 プロンプトエンジニアリング"}, {"category": "Chapter 2", "question": "大規模言語モデル（LLM）の出力をより人間の意図に沿った、安全で有用なものにするために、人間の評価者が複数のAIの回答をランク付けし、そのフィードバックを基にモデルを改善していく学習手法を何と呼びますか？", "answers": ["教師あり学習", "自己教師あり学習", "人間のフィードバックからの強化学習 (RLHF)", "敵対的学習"], "correctAnswer": "人間のフィードバックからの強化学習 (RLHF)", "explanation": "RLHF (Reinforcement Learning from Human Feedback) は、ChatGPTなどの高度な対話AIの性能向上に大きく貢献した技術です。人間の価値観をAIに教え込み、より望ましい応答を生成するように導きます。", "source": "第2章 大規模言語モデルの学習手法"}, {"category": "Chapter 2", "question": "文章の続きを予測するように学習されたGPTのようなモデルは、どのようなアーキテクチャに基づいていますか？", "answers": ["Transformerのエンコーダのみ", "Transformerのデコーダのみ", "Transformerのエンコーダとデコーダの両方", "RNNとCNNの組み合わせ"], "correctAnswer": "Transformerのデコーダのみ", "explanation": "GPT（Generative Pre-trained Transformer）は、その名の通りTransformerのデコーダ部分を基本としています。デコーダは、それまでに出力された単語列を条件に、次に来る単語を予測する自己回帰的な動作に特化しており、文章生成に適しています。", "source": "第2章 大規模言語モデル (GPT)"}, {"category": "Chapter 2", "question": "文章全体の文脈を理解することに長けており、文中の単語の穴埋め問題（マスク化言語モデル）を解くように学習されることで、文章の分類や固有表現抽出などのタスクで高い性能を発揮するモデルはどれですか？", "answers": ["GPT", "BERT", "DALL-E", "LaMDA"], "correctAnswer": "BERT", "explanation": "BERT (Bidirectional Encoder Representations from Transformers) は、Transformerのエンコーダ部分を利用し、文章を双方向（左から右、右から左）から同時に処理することで、単語の文脈上の意味を深く理解します。", "source": "第2章 大規模言語モデル (BERT)"}, {"category": "Chapter 2", "question": "生成AIのモデルサイズが非常に大きくなり、高性能なGPUを多数必要とすることが課題となっています。この課題に対応するため、モデルの性能をある程度維持しつつ、パラメータ数や計算量を削減する技術の総称は何ですか？", "answers": ["モデルの軽量化・効率化", "モデルの巨大化", "マルチモーダル化", "汎用化"], "correctAnswer": "モデルの軽量化・効率化", "explanation": "モデルの軽量化・効率化技術には、パラメータの一部を削減する「枝刈り（Pruning）」、パラメータの精度を落とす「量子化（Quantization）」、大きなモデルの知識を小さなモデルに受け継がせる「蒸留（Distillation）」など、様々なアプローチがあります。", "source": "第2章 生成AIの技術的課題"}, {"category": "Chapter 2", "question": "テキストだけでなく、画像、音声、動画など、複数の異なる種類のデータ（モダリティ）を統合的に扱うことができるAIモデルを何と呼びますか？", "answers": ["シングルモーダルAI", "マルチモーダルAI", "トランスモーダルAI", "クロスモーダルAI"], "correctAnswer": "マルチモーダルAI", "explanation": "マルチモーダルAIは、例えば「犬が吠えている画像」を見て、「犬の鳴き声」の音声を生成したり、テキストと画像を組み合わせて新しいコンテンツを生成したりすることができます。より人間に近い、複合的な情報処理を実現する技術として注目されています。", "source": "第2章 生成AIの発展技術"}, {"category": "Chapter 2", "question": "プロンプトエンジニアリングにおいて、AIに具体的な回答例をいくつか提示してから本題の質問をすることで、AIがタスクの意図をより正確に理解し、望ましい形式で回答を生成しやすくなる手法を何と呼びますか？", "answers": ["Zero-shotプロンプティング", "Few-shotプロンプティング", "Chain-of-Thoughtプロンプティング", "Self-Consistency"], "correctAnswer": "Few-shotプロンプティング", "explanation": "Few-shotプロンプティングは、AIにタスクの「お手本」を少数（few）見せるアプローチです。これにより、AIはどのような形式で、どのような内容を答えればよいかを学習し、出力の質が向上します。", "source": "第2章 プロンプトエンジニアリングの手法"}, {"category": "Chapter 2", "question": "複雑な推論問題に対して、AIに「ステップ・バイ・ステップで考えてください」のように、思考のプロセスを文章化させることで、最終的な回答の精度を高めるプロンプト技術を何と呼びますか？", "answers": ["ReActプロンプティング", "Few-shotプロンプティング", "Zero-shotプロンプティング", "Chain-of-Thought (CoT) プロンプティング"], "correctAnswer": "Chain-of-Thought (CoT) プロンプティング", "explanation": "Chain-of-Thought（思考の連鎖）は、AIに中間的な思考プロセスを生成させることで、複雑な問題でも論理的に分解して考えられるように促す手法です。これにより、算術問題や論理パズルなどの正解率が飛躍的に向上することが知られています。", "source": "第2章 プロンプトエンジニアリングの手法"}, {"category": "Chapter 2", "question": "GAN（敵対的生成ネットワーク）の学習プロセスにおいて、生成器が識別器を騙しやすい、ごく一部の多様性に欠けるデータばかりを生成するようになってしまう問題を何と呼びますか？", "answers": ["勾配消失問題", "モード崩壊 (Mode Collapse)", "過学習", "ハルシネーション"], "correctAnswer": "モード崩壊 (Mode Collapse)", "explanation": "モード崩壊は、生成されるデータの多様性が失われ、同じような画像や文章ばかりが出力される現象です。GANの学習を不安定にさせる主要な課題の一つであり、様々な改良手法が提案されています。", "source": "第2章 代表的な生成モデル (GAN)"}, {"category": "Chapter 2", "question": "入力されたデータ（例えば画像）を、より低次元の潜在空間に一度圧縮し、その圧縮された情報から元のデータを復元するように学習するニューラルネットワークのアーキテクチャは何ですか？データの次元削減や特徴抽出に利用されます。", "answers": ["敵対的生成ネットワーク (GAN)", "オートエンコーダ (AE)", "Transformer", "回帰型ニューラルネットワーク (RNN)"], "correctAnswer": "オートエンコーダ (AE)", "explanation": "オートエンコーダは、入力データ自身を教師データとして学習する自己教師あり学習の一種です。データを圧縮する部分をエンコーダ、復元する部分をデコーダと呼びます。この構造を発展させた変分オートエンコーダ（VAE）は、代表的な生成モデルの一つです。", "source": "第2章 代表的な生成モデル (オートエンコーダ)"}, {"category": "Chapter 2", "question": "ある言語モデルが、大量のテキストデータを学習する際に、文中のある単語が、その前後（左右両方）の単語からどのように影響を受けているかを考慮して、その単語の意味表現を学習しています。この学習方法を何と呼びますか？", "answers": ["自己回帰 (Autoregressive)", "双方向 (Bidirectional)", "自己符号化 (Autoencoding)", "敵対的 (Adversarial)"], "correctAnswer": "双方向 (Bidirectional)", "explanation": "BERTに代表される双方向モデルは、文脈を左右両方から捉えることで、同じ単語でも文脈によって異なる意味を深く理解することができます。例えば、「銀行に行く」と「川の土手（bank）を歩く」のbankの違いを区別できます。", "source": "第2章 大規模言語モデル (BERT)"}, {"category": "Chapter 2", "question": "ある開発者が、画像生成AIを用いて「馬に乗った宇宙飛行士」の画像を生成しようとしています。このとき、開発者がAIに与える「馬に乗った宇宙飛行士」というテキスト指示のことを、特に何と呼びますか？", "answers": ["パラメータ", "ウェイト（重み）", "プロンプト", "メタデータ"], "correctAnswer": "プロンプト", "explanation": "プロンプトは、生成AIに対して何を生成してほしいかを伝えるための入力テキストや指示です。効果的なプロンプトを作成する技術（プロンプトエンジニアリング）は、生成AIをうまく活用する上で非常に重要です。", "source": "第2章 プロンプトエンジニアリング"}, {"category": "Chapter 2", "question": "インターネット上の膨大なテキストと画像（キャプション付き）のペアを学習することで、テキストの指示（プロンプト）に基づいて高品質な画像を生成できるようになったモデルのカテゴリは何ですか？", "answers": ["言語モデル (LM)", "視覚言語モデル (Vision-Language Model)", "音声認識モデル (ASR)", "翻訳モデル (MT)"], "correctAnswer": "視覚言語モデル (Vision-Language Model)", "explanation": "DALL-EやStable Diffusionに代表される視覚言語モデルは、テキストと画像という異なるモダリティの関係性を学習しています。これにより、「テキストから画像へ」という、従来は困難だったタスクを高精度で実現できるようになりました。", "source": "第2章 生成AIの発展技術 (マルチモーダルAI)"}, {"category": "Chapter 2", "question": "生成AIの基盤となっているTransformerアーキテクチャにおいて、入力された単語の順序情報をモデルに与えるために、各単語のベクトルに付加される位置情報を何と呼びますか？", "answers": ["位置エンコーディング (Positional Encoding)", "単語埋め込み (Word Embedding)", "アテンション・ウェイト (Attention Weight)", "トークンID"], "correctAnswer": "位置エンコーディング (Positional Encoding)", "explanation": "Transformerは、RNNのような再帰的な構造を持たないため、そのままでは単語の順序を理解できません。そのため、各単語の位置を示す情報をベクトルとして加え、単語の順序情報をモデルに供給しています。", "source": "第2章 Transformerとアテンション機構"}, {"category": "Chapter 2", "question": "大規模な基盤モデルを、スマートフォンなどのリソースが限られたデバイス上で動作させるために、モデルの精度への影響を最小限に抑えながら、そのサイズを圧縮する技術の一つは何ですか？", "answers": ["蒸留 (Distillation)", "転移学習 (Transfer Learning)", "強化学習 (Reinforcement Learning)", "事前学習 (Pre-training)"], "correctAnswer": "蒸留 (Distillation)", "explanation": "蒸留は、大規模で高精度な「教師モデル」の知識を、より小さく軽量な「生徒モデル」に転移させる技術です。生徒モデルは、教師モデルの出力（ソフトターゲット）を真似るように学習することで、サイズが小さいにもかかわらず高い性能を達成できます。", "source": "第2章 生成AIの技術的課題 (モデルの軽量化)"}, {"category": "Chapter 2", "question": "GPT-3のような非常に巨大なモデルをファインチューニングする際、全てのパラメータを更新するのではなく、ごく一部の追加パラメータのみを学習することで、計算コストを大幅に削減する効率的な手法は何ですか？", "answers": ["LoRA (Low-Rank Adaptation)", "Dropout", "Batch Normalization", "Adam"], "correctAnswer": "LoRA (Low-Rank Adaptation)", "explanation": "LoRAは、Parameter-Efficient Fine-Tuning (PEFT) と呼ばれる手法群の一つです。元のモデルの重みは固定したまま、小さな追加層（アダプタ）の重みだけを学習することで、少ない計算資源で効率的にファインチューニングを行うことができます。", "source": "第2章 基盤モデルとその活用"}, {"category": "Chapter 2", "question": "生成AIに「悲しい物語を書いて」と指示するだけでなく、「主人公は雨の日に失恋した猫です。文体は簡潔で、詩的にしてください。」のように、より詳細な条件や制約を与えることで、出力の質をコントロールするアプローチを何と呼びますか？", "answers": ["制約付き生成", "無制約生成", "敵対的生成", "確率的生成"], "correctAnswer": "制約付き生成", "explanation": "これはプロンプトエンジニアリングの基本的な考え方の一つで、AIに対して明確な制約や文脈を与えることで、より意図に沿った、質の高いコンテンツを生成させるテクニックです。", "source": "第2章 プロンプトエンジニアリング"}, {"category": "Chapter 2", "question": "ある言語モデルが「空の色は青い」という事実を学習しているとします。このモデルの内部で、「空」「色」「青い」といった単語や概念が、どのような形で表現されていると考えられますか？", "answers": ["人間が理解できるルール（if-then形式）", "高次元の数値ベクトル（分散表現）", "単純なID番号", "音声波形データ"], "correctAnswer": "高次元の数値ベクトル（分散表現）", "explanation": "現代の言語モデルは、単語や概念を「単語埋め込み」と呼ばれる高次元のベクトルで表現します。このベクトル空間上で、意味が近い単語は近くに配置され、意味的な関係性がベクトルの演算として捉えられるようになっています。", "source": "第2章 大規模言語モデルの内部表現"}, {"category": "Chapter 2", "question": "画像生成AIであるStable Diffusionは、ユーザーが入力したプロンプト（テキスト）と、ランダムに生成されたノイズの両方を入力として、画像を生成します。この仕組みがもたらす主な利点は何ですか？", "answers": ["常に同じプロンプトからは全く同じ画像が生成されるため、再現性が高い", "ランダムノイズの要素が加わることで、同じプロンプトからでも多様なバリエーションの画像を生成できる", "プロンプトがなくても、ランダムノイズだけで意味のある画像を生成できる", "計算コストが大幅に削減できる"], "correctAnswer": "ランダムノイズの要素が加わることで、同じプロンプトからでも多様なバリエーションの画像を生成できる", "explanation": "拡散モデルでは、潜在変数としてランダムノイズ（シード値）を用いることで、生成プロセスに確率的な多様性をもたらします。これにより、ユーザーは同じテキスト指示から、少しずつ異なる多様な画像を生成し、好みの結果を選択することができます。", "source": "第2章 代表的な生成モデル (拡散モデル)"}, {"category": "Chapter 2", "question": "「基盤モデル」という概念の登場によって、AI開発のパラダイムはどのように変化したと説明できますか？", "answers": ["すべてのAIモデルを、タスクごとにゼロから開発する必要があるようになった", "一つの巨大な事前学習済みモデルを、様々なタスクに「適応」させるアプローチが主流になった", "AI開発には、もはや人間のエンジニアは不要になった", "小規模なデータセットだけで、高性能なAIを開発できるようになった"], "correctAnswer": "一つの巨大な事前学習済みモデルを、様々なタスクに「適応」させるアプローチが主流になった", "explanation": "基盤モデルの登場以前は、タスクごとに大量の教師データを用意し、モデルを個別に学習させるのが一般的でした。基盤モデルの登場により、汎用的な能力を持つモデルをファインチューニングすることで、より効率的に多様なタスクに対応できるようになりました。", "source": "第2章 基盤モデルとその影響"}, {"category": "Chapter 4", "question": "生成AIに「日本の首都について教えてください」と質問したところ、「日本の首都は京都です。江戸時代に東京に遷都されるまで、1000年以上にわたり政治と文化の中心でした」という、事実とは異なるもっともらしい回答が生成されました。このような現象を何と呼びますか？", "answers": ["アルゴリズム的バイアス", "モード崩壊", "ハルシネーション（幻覚）", "敵対的攻撃"], "correctAnswer": "ハルシネーション（幻覚）", "explanation": "ハルシネーションは、生成AIが学習データに含まれない、事実に基づかない情報を、あたかも事実であるかのように生成してしまう現象です。生成AIを利用する上で、情報の真偽を確認（ファクトチェック）することの重要性を示唆しています。", "source": "第4章 生成AIの課題とリスク"}, {"category": "Chapter 4", "question": "ある採用支援システムに過去の採用実績データを学習させたところ、特定の性別や出身大学の応募者を不当に低く評価する傾向が見られました。このような、AIが学習データに含まれる社会的な偏見を反映・増幅してしまう問題を何と呼びますか？", "answers": ["ハルシネーション", "アルゴリズム的バイアス", "プライバシー侵害", "ブラックボックス問題"], "correctAnswer": "アルゴリズム的バイアス", "explanation": "アルゴリズム的バイアスは、データに潜む偏見をAIが学習することで、特定のグループに対して不公平な結果を生み出してしまう問題です。AIを開発・利用する際には、公平性を確保するための対策が不可欠です。", "source": "第4章 AI倫理における重要課題"}, {"category": "Chapter 4", "question": "AIを利用した自動運転車が事故を起こした場合、その責任は車の所有者、製造メーカー、AI開発者の誰にあるのか、という問題が議論されています。このような、AIシステムの判断や行動の結果に対する責任の所在を問う概念を何と呼びますか？", "answers": ["公平性 (Fairness)", "透明性 (Transparency)", "アカウンタビリティ (Accountability)", "堅牢性 (Robustness)"], "correctAnswer": "アカウンタビリティ (Accountability)", "explanation": "アカウンタビリティは「説明責任」と訳され、AIシステムの振る舞いをステークホルダー（利害関係者）に説明できる状態を指します。AIが社会に受け入れられるために、技術的な側面だけでなく、法整備や社会的なルール作りが求められる重要な論点です。", "source": "第4章 AI倫理の主要原則"}, {"category": "Chapter 4", "question": "ディープラーニングモデルは、なぜその結論に至ったのかの判断根拠を人間が理解するのが難しいという性質を持つことがあります。この問題を指す言葉として、最も適切なものはどれですか？", "answers": ["ホワイトボックス問題", "ブラックボックス問題", "NP困難問題", "アラインメント問題"], "correctAnswer": "ブラックボックス問題", "explanation": "モデルの内部構造が非常に複雑であるため、入力と出力の関係性が人間には直感的に理解できず、まるで「黒い箱」のように見えることからこう呼ばれます。この問題に対処するため、判断根拠を可視化・説明する「説明可能なAI（XAI）」の研究が進められています。", "source": "第4章 AI倫理の主要原則（透明性と説明可能性）"}, {"category": "Chapter 4", "question": "ある政治家の偽の動画がSNSで拡散され、社会的な混乱を引き起こしました。この動画は、生成AIを用いて本物の映像や音声から精巧に作成されたものでした。このような偽のコンテンツを作成・悪用する技術を特に何と呼びますか？", "answers": ["ハルシネーション", "ディープフェイク", "デジタルツイン", "アバター"], "correctAnswer": "ディープフェイク", "explanation": "ディープフェイクは、ディープラーニングとフェイク（偽物）を組み合わせた造語です。エンターテイメントへの応用が期待される一方、偽情報の拡散や名誉毀損など、社会を混乱させる目的で悪用されるリスクが大きな社会問題となっています。", "source": "第4章 生成AIの社会的影響と悪用リスク"}, {"category": "Chapter 4", "question": "ある企業が、自社のウェブサイトに顧客からの問い合わせに24時間対応するチャットボットを導入しました。このチャットボットは、顧客からの質問の意図を理解し、関連するFAQを提示したり、適切な担当者へ引き継いだりします。これは生成AIのどのような活用例に該当しますか？", "answers": ["コンテンツ制作の自動化", "業務プロセスの自動化・効率化", "データ分析の高度化", "新規事業・サービスの創出"], "correctAnswer": "業務プロセスの自動化・効率化", "explanation": "カスタマーサポート業務の一部をAIが担うことで、24時間対応の実現や、人間のオペレーターがより複雑な問い合わせに集中できるといったメリットが生まれます。これは、既存の業務プロセスをAIで効率化する典型的な例です。", "source": "第4章 生成AIのビジネス活用"}, {"category": "Chapter 4", "question": "ある開発者が、生成AIを用いて新しいスマートフォンアプリのUIデザイン案を複数生成し、その中から最も優れたものを選択して開発を進めました。この活用方法は、主にどの価値をもたらすものですか？", "answers": ["コスト削減", "パーソナライゼーションの向上", "創造性の拡張とアイデア創出の支援", "リスク管理の強化"], "correctAnswer": "創造性の拡張とアイデア創出の支援", "explanation": "生成AIは、人間だけでは思いつかなかったような多様なデザイン案を短時間で大量に生成することができます。これにより、人間のデザイナーは創造的な探求に多くの時間を費やすことができ、最終的なアウトプットの質を高めることができます。", "source": "第4章 生成AIのビジネス活用"}, {"category": "Chapter 4", "question": "生成AIの導入を検討していますが、機密情報や個人情報が外部のAIサービスに送信されることによる情報漏洩を懸念しています。このリスクへの対策として、適切でないものはどれですか？", "answers": ["入力するデータから機密情報や個人情報を事前にマスキング（匿名化）する", "外部のクラウドサービスを利用せず、自社内の閉じた環境（オンプレミス）にAIモデルを構築する", "従業員に対して、機密情報をプロンプトに含めないように周知・教育する", "利便性を最優先し、情報セキュリティに関するルールは設けない"], "correctAnswer": "利便性を最優先し、情報セキュリティに関するルールは設けない", "explanation": "生成AIの利便性は高いですが、情報セキュリティのリスクを無視することはできません。企業の機密情報や顧客の個人情報を保護するためには、利用ルールの策定、従業員教育、技術的な対策（アクセス制御やデータ匿名化など）を組み合わせることが不可欠です。", "source": "第4章 生成AIの導入におけるリスク管理"}, {"category": "Chapter 4", "question": "生成AIが作成した文章や画像の著作権の帰属について、日本の現行法における一般的な考え方として、最も適切なものはどれですか？", "answers": ["生成AIを開発した企業に著作権が帰属する", "生成AIに指示（プロンプト）を与えた利用者に著作権が帰属する", "AIは「思想又は感情を創作的に表現したもの」の主体とはなり得ないため、AIが自律的に生成したものには、原則として著作権は発生しない", "生成されたコンテンツはすべてパブリックドメインとなる"], "correctAnswer": "AIは「思想又は感情を創作的に表現したもの」の主体とはなり得ないため、AIが自律的に生成したものには、原則として著作権は発生しない", "explanation": "日本の著作権法では、著作物は「思想又は感情を創作的に表現したもの」と定義されており、その創作の主体は人間であると解釈されています。そのため、AIが自動生成しただけのものには、原則として著作権は認められません。ただし、プロンプトの作成に人間の創作的な寄与が認められる場合などは、そのプロンプトが著作物となる可能性はあります。", "source": "第4章 生成AIと著作権"}, {"category": "Chapter 4", "question": "あるイラストレーターが、自身の画風に酷似した画像を生成する画像生成AIが公開されたことにより、仕事が奪われるのではないかと懸念しています。このような、AIが人間の仕事を代替することによる社会的な問題を何と呼びますか？", "answers": ["デジタルデバイド（情報格差）", "雇用の代替とスキルシフト", "フィルターバブル", "エコーチェンバー"], "correctAnswer": "雇用の代替とスキルシフト", "explanation": "AIや自動化技術の進展により、特定の職種やタスクがAIに代替される可能性が指摘されています。一方で、AIを使いこなす新しいスキルや、AIにはできない創造性・コミュニケーション能力などがより重要になると考えられており、社会全体でのスキルの移行（スキルシフト）が課題となっています。", "source": "第4章 生成AIが社会・経済に与える影響"}, {"category": "Chapter 4", "question": "EU（欧州連合）が制定を目指している「AI法（AI Act）」に関する説明として、最も適切なものはどれですか？", "answers": ["すべてのAIの利用を全面的に禁止する法律である", "AIがもたらすリスクを4段階に分類し、リスクレベルに応じて異なる規制を課すアプローチを取っている", "AI開発企業に対して、ソースコードの全面的な公開を義務付けるものである", "生成AIの著作権は、すべてAI開発者に帰属すると定めている"], "correctAnswer": "AIがもたらすリスクを4段階に分類し、リスクレベルに応じて異なる規制を課すアプローチを取っている", "explanation": "EUのAI法は、AIのリスクを「許容できないリスク」「ハイリスク」「限定的なリスク」「最小限のリスク」に分類する、リスクベースのアプローチが特徴です。例えば、サブリミナルな操作を行うAIは「許容できないリスク」として原則禁止される一方、多くのAIアプリケーションは「最小限のリスク」として自由な利用が認められます。", "source": "第4章 AIに関する法規制とガイドライン"}, {"category": "Chapter 4", "question": "機械学習モデルの開発から運用、そして再学習までの一連のライフサイクルを、安定的かつ効率的に管理・自動化するための考え方やプラクティスを何と呼びますか？", "answers": ["DevOps", "MLOps (Machine Learning Operations)", "DataOps", "AIOps"], "correctAnswer": "MLOps (Machine Learning Operations)", "explanation": "MLOpsは、ソフトウェア開発の効率化手法であるDevOpsの考え方を、機械学習の分野に応用したものです。モデルの性能監視、再学習の自動化、バージョニング管理などを通じて、AIモデルの品質と信頼性を継続的に維持することを目的とします。", "source": "第4章 MLOps（機械学習基盤）"}, {"category": "Chapter 4", "question": "あるユーザーが、生成AIチャットボットとの対話の中で、自身の病歴や個人情報を詳しく話してしまいました。このユーザーが、AIサービス提供企業に対して、自身の個人データを削除するように要求する権利は、主にどの法律や原則に基づいていますか？", "answers": ["著作権法", "不正競争防止法", "EU一般データ保護規則（GDPR）における「忘れられる権利」", "製造物責任法（PL法）"], "correctAnswer": "EU一般データ保護規則（GDPR）における「忘れられる権利」", "explanation": "GDPRに定められる「忘れられる権利」は、個人が自己に関するデータの削除を管理者に要求できる権利です。日本の個人情報保護法にも同様の趣旨の規定が含まれており、ユーザーは自身のプライバシーをコントロールする権利を持っています。", "source": "第4章 AIとプライバシー保護"}, {"category": "Chapter 4", "question": "生成AIが出力した文章を、そのまま自身のレポートやブログ記事として公開した場合、どのような問題が指摘される可能性がありますか？", "answers": ["AIの利用は常に倫理的であるため、何の問題もない", "盗用（剽窃）や著作権侵害にあたる可能性や、内容に誤りが含まれているリスクがある", "AIの電気代が高額になる", "他の人が同じAIを使えなくなる"], "correctAnswer": "盗用（剽窃）や著作権侵害にあたる可能性や、内容に誤りが含まれているリスクがある", "explanation": "生成AIの出力は、学習データに基づいています。そのため、意図せず既存のコンテンツと酷似した内容が出力される可能性があります。また、ハルシネーションによる誤情報も含まれ得ます。AIの生成物をそのまま利用するのではなく、あくまで「下書き」や「たたき台」として扱い、自身の言葉で表現し直し、ファクトチェックを行う責任ある態度が求められます。", "source": "第4章 生成AIの責任ある利用"}, {"category": "Chapter 4", "question": "AIシステムの開発・運用において、入力データやモデルのパラメータ、学習プロセスなどを記録・管理し、問題が発生した際にその原因を追跡できるようにしておくことの重要性を示す概念はどれですか？", "answers": ["トレーサビリティ（追跡可能性）", "スケーラビリティ（拡張可能性）", "ユーザビリティ（利用可能性）", "アベイラビリティ（可用性）"], "correctAnswer": "トレーサビリティ（追跡可能性）", "explanation": "トレーサビリティは、AIシステムの透明性とアカウンタビリティ（説明責任）を確保するための重要な要素です。モデルが予期せぬ振る舞いをした際に、どのようなデータで、どのように学習されたかを遡って調査できることは、原因究明と再発防止に不可欠です。", "source": "第4章 MLOpsとAIガバナンス"}, {"category": "Chapter 4", "question": "ある自治体が、地域の観光振興のために、生成AIを使って観光スポットを紹介する記事を自動生成するシステムを導入しました。このシステムの導入効果として、最も期待できるものはどれですか？", "answers": ["観光客のプライバシー情報を収集できる", "多言語での情報発信を迅速かつ低コストで実現できる", "地域のすべての宿泊施設が常に満室になる", "AIが観光地の新たな歴史的事実を発見する"], "correctAnswer": "多言語での情報発信を迅速かつ低コストで実現できる", "explanation": "生成AIの翻訳能力や文章生成能力を活用することで、多様な言語の観光情報を効率的に作成・更新できます。これにより、海外からの観光客誘致や、情報発信の迅速化に繋がり、観光振興に貢献することが期待されます。", "source": "第4章 生成AIの具体的な応用例"}, {"category": "Chapter 4", "question": "あるニュースメディアが、記事の要約を生成AIに作成させています。しかし、元の記事にはない扇情的な表現や、誤解を招くような要約が生成されることがあり、問題となっています。この問題を防ぐために、メディアが取るべき対策として最も適切なものはどれですか？", "answers": ["生成された要約を、人間の編集者が必ず確認・修正するプロセスを導入する", "AIの学習データを、より扇情的な記事に限定する", "要約の文字数を可能な限り短くするようにAIに指示する", "AIが生成したものであることを読者に隠す"], "correctAnswer": "生成された要約を、人間の編集者が必ず確認・修正するプロセスを導入する", "explanation": "生成AIは便利なツールですが、その出力が常に正確で適切であるとは限りません。特に、情報の正確性や公平性が求められる報道のような分野では、AIの生成物を人間が監督し、最終的な責任を持つ体制（Human-in-the-loop）が不可欠です。", "source": "第4章 生成AIの責任ある利用"}, {"category": "Chapter 4", "question": "AIモデルのライフサイクル全体にわたって、公平性、透明性、説明責任などを確保し、リスクを管理するための組織的な仕組みやプロセスを何と呼びますか？", "answers": ["AIガバナンス", "AIプロトコル", "AIマニフェスト", "AIシンドローム"], "correctAnswer": "AIガバナンス", "explanation": "AIガバナンスは、AIを倫理的かつ責任ある形で開発・利用するための組織的な統治の仕組みです。これには、AI利用ガイドラインの策定、倫理委員会の設置、リスク評価プロセスの導入などが含まれます。", "source": "第4章 企業におけるAIガバナンス"}, {"category": "Chapter 4", "question": "あるユーザーが画像生成AIに「アニメ風の少女」と入力したところ、特定の身体的特徴が強調された画像ばかりが生成される傾向がありました。これはAIのどのような問題に関連していますか？", "answers": ["学習データに内在するバイアス", "モデルの計算能力不足", "プロンプトの具体性の欠如", "著作権侵害のリスク"], "correctAnswer": "学習データに内在するバイアス", "explanation": "AIは学習データに含まれるパターンを反映します。もし学習データに、特定のステレオタイプを強調するような画像が多く含まれていれば、AIもそのステレオタイプを再生産・増幅してしまう可能性があります。これはアルゴリズム的バイアスの一例です。", "source": "第4章 AI倫理における重要課題 (バイアス)"}, {"category": "Chapter 4", "question": "生成AIの利用が拡大する中で、AIを使いこなせる人とそうでない人の間に、経済的・社会的な格差が生じる可能性が懸念されています。このような格差を何と呼びますか？", "answers": ["デジタルデバイド", "フィルターバブル", "AIデバイド", "ジェネレーションギャップ"], "correctAnswer": "AIデバイド", "explanation": "AIデバイドは、デジタルデバイド（情報格差）のAI版と言えます。AI技術へのアクセスや、それを活用するスキルの有無が、個人のキャリアや企業の競争力に大きな差を生む可能性があり、教育やリスキリングの重要性が指摘されています。", "source": "第4章 生成AIが社会・経済に与える影響"}, {"category": "Chapter 4", "question": "あるソフトウェア開発企業が、生成AIを用いてプログラムコードを自動生成するサービスを導入しました。このサービスの利用規約には、「生成されたコードの品質、正確性、およびセキュリティについて、当社は一切の保証をしません」と記載されていました。このような免責事項が設けられる主な理由は何ですか？", "answers": ["生成AIは完璧であり、バグのあるコードを生成することは絶対にないから", "生成されたコードには、脆弱性が含まれていたり、意図通りに動作しない可能性があるため、最終的な責任は利用者が負うべきだから", "生成されたコードの著作権は、すべてAI開発企業に帰属するため", "利用者にサービス料金を高く請求するため"], "correctAnswer": "生成されたコードには、脆弱性が含まれていたり、意図通りに動作しない可能性があるため、最終的な責任は利用者が負うべきだから", "explanation": "生成AIは非常に強力ですが、その出力は常に正しいとは限りません。コード生成の場合、一見正しく見えても、セキュリティ上の欠陥や稀なケースで発生するバグを含んでいる可能性があります。そのため、多くのサービスでは、生成物の最終的な確認と責任は利用者が負うことを明確にしています。", "source": "第4章 生成AIの利用における注意点"}, {"category": "Chapter 4", "question": "あるアーティストが、自身の作品を画像生成AIの学習に利用されることを望まない場合、その意思を示すための一般的な方法として、どのようなものがありますか？", "answers": ["自身のウェブサイトに「AI学習禁止」とテキストで表示する", "作品の画像データに、AIによる読み取りを拒否するメタデータを付与する（例: \"noai\"タグ）", "すべての作品をインターネット上から削除する", "AI開発企業に対して、個別に電話ですべて連絡する"], "correctAnswer": "作品の画像データに、AIによる読み取りを拒否するメタデータを付与する（例: \"noai\"タグ）", "explanation": "クリエイターがAIの学習から自身の作品を除外する意思を示すための技術的な試みとして、ウェブサイトのクローラー向けの指示（robots.txt）や、画像自体にメタデータを埋め込む方法などが議論・実装されつつあります。ただし、これらが法的な拘束力を持つか、またすべてのAI開発者が遵守するかは、まだ発展途上の領域です。", "source": "第4章 生成AIとクリエイターの権利"}, {"category": "Chapter 4", "question": "生成AIの活用方法の一つに「データ拡張（Data Augmentation）」があります。これはどのような目的で行われますか？", "answers": ["AIの学習に必要な計算資源を増やすため", "少量の元データから、多様なバリエーションを持つ学習データを人工的に生成し、AIモデルの汎化性能と頑健性を向上させるため", "AIの学習データを、より小さなサイズに圧縮するため", "AIの回答速度を速めるため"], "correctAnswer": "少量の元データから、多様なバリエーションを持つ学習データを人工的に生成し、AIモデルの汎化性能と頑健性を向上させるため", "explanation": "例えば、医療画像診断AIを学習させる際、希少な症例の画像データは少数しか手に入らないことがあります。このような場合に、生成AIを用いて本物に近い偽の医療画像を大量に生成し、学習データの量を増やすことで、モデルの精度を向上させることができます。", "source": "第4章 生成AIの応用分野"}, {"category": "Chapter 4", "question": "ある企業が、AI倫理に関する基本方針を策定しました。この方針を社内に浸透させ、実際の製品開発やサービス提供の場面で遵守されるようにするために、次に取るべき行動として最も効果的なものはどれですか？", "answers": ["方針を策定したことだけを社内イントラネットで告知し、あとは従業員の自主性に任せる", "具体的なケーススタディを用いた研修を実施し、従業員が自分事として考える機会を提供する", "AI倫理に違反した従業員に対して、厳しい罰則規定を設けることだけを強調する", "AI倫理は重要ではないので、特に何もしない"], "correctAnswer": "具体的なケーススタディを用いた研修を実施し、従業員が自分事として考える機会を提供する", "explanation": "ガイドラインや方針は、策定するだけでは意味がありません。従業員一人ひとりがその重要性を理解し、日々の業務の中でどのように実践すべきかを具体的にイメージできるように、継続的な教育や対話の場を設けることが、組織文化として定着させる鍵となります。", "source": "第4章 AIガバナンスと組織文化"}, {"category": "Chapter 4", "question": "生成AIが出力した文章を、そのまま自身のレポートやブログ記事として公開した場合、どのような問題が指摘される可能性がありますか？", "answers": ["AIの利用は常に倫理的であるため、何の問題もない", "盗用（剽窃）や著作権侵害にあたる可能性や、内容に誤りが含まれているリスクがある", "AIの電気代が高額になる", "他の人が同じAIを使えなくなる"], "correctAnswer": "盗用（剽窃）や著作権侵害にあたる可能性や、内容に誤りが含まれているリスクがある", "explanation": "生成AIの出力は、学習データに基づいています。そのため、意図せず既存のコンテンツと酷似した内容が出力される可能性があります。また、ハルシネーションによる誤情報も含まれ得ます。AIの生成物をそのまま利用するのではなく、あくまで「下書き」や「たたき台」として扱い、自身の言葉で表現し直し、ファクトチェックを行う責任ある態度が求められます。", "source": "第4章 生成AIの責任ある利用"}, {"category": "Chapter 4", "question": "AIシステムの開発・運用において、入力データやモデルのパラメータ、学習プロセスなどを記録・管理し、問題が発生した際にその原因を追跡できるようにしておくことの重要性を示す概念はどれですか？", "answers": ["トレーサビリティ（追跡可能性）", "スケーラビリティ（拡張可能性）", "ユーザビリティ（利用可能性）", "アベイラビリティ（可用性）"], "correctAnswer": "トレーサビリティ（追跡可能性）", "explanation": "トレーサビリティは、AIシステムの透明性とアカウンタビリティ（説明責任）を確保するための重要な要素です。モデルが予期せぬ振る舞いをした際に、どのようなデータで、どのように学習されたかを遡って調査できることは、原因究明と再発防止に不可欠です。", "source": "第4章 MLOpsとAIガバナンス"}]